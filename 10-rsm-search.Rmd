# Search and classification performances {#rsm-sc}


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(kableExtra)
library(RJafroc)
library(ggplot2)
library(grid)
```



## TBA How much finished {#rsm-sc-how-much-finished}

70%
Intro



## TBA Introduction {#rsm-sc-intro}

The preceding two chapters described the ROC and other predictions of the radiological search model (RSM). This chapter describes two key performance metrics, These are search and Lesion-classification performances, that can be derived from the end-point of the predicted ROC curve and relates them to RSM parameters. We start by recapitulating the formulae for the location of the RSM-predicted end-point. 

## Location of ROC end-point {#rsm-sc-end-point}

From Chapter \@ref(rsm-predictions) the coordinates of the RSM-predicted ROC end-point are given by:

\begin{equation}
\left. 
\begin{aligned}
&\text{FPF}_{\text{max}} = 1 - \text{exp}\left (\lambda \right ) \\
&\text{TPF}_{\text{max}} = 1 - \text{exp} \left ( - \lambda \right )\sum_{L=1}^{L_{max}}f_L \left ( 1 - \nu \right )^L
\end{aligned}
\right \}
(\#eq:rsm-sc-FPF-TPF-max)
\end{equation}




## Quantifying search performance {#rsm-sc-quantifying}

Qualitatively, search performance is the ability to find lesions while not finding non-lesions. To arrive at a quantitative definition of search performance consider the location of the ROC end-point defined above. 

In Fig. \@ref(fig:rsm-sc-performance-from-roc-curve) plot (a) is a typical ROC curve predicted by models that do not account for search, specifically the binormal model is considered here. The end-point is at (1,1), the filled circle, i.e., by adopting a sufficiently low reporting threshold the observer can continuously move the operating point to (1,1). The curve labeled (b) is a typical RSM-predicted ROC curve. The end-point, the filled square, is downwards and left shifted relative to (1,1). The chance diagonal is labeled c. 

The specific parameter values used in the illustration are shown next:


```{r}
a <- 2; b <- 1 # binormal model
mu <- 2; lambda_i <- 2; nu_i <- 1 # rsm
lesDistr <- c(1) # one lesion per dis. case
```




```{r rsm-sc-performance-from-roc-curve, fig.cap="Relation of search performance to the end-point of the ROC curve. Plot (a) is using the binormal model while plot (b) is using a RSM predicted curve. The chance diagonal is labeled c. The filled square is the end-point of the RSM predicted curve while the filled dot is the end-point of the binormal predicted curve. The distance of the filled square from the chance diagonal, labeled $d_S$, is a measure of search performance.", echo = FALSE}

plotZeta <- seq(-20, 20, by = 0.01)
lambda <- lambda_i / mu
if (abs(nu_i * mu) <= 1e-6 ) nu <- 1e-6 else nu <- (1-exp(-nu_i * mu))

fpfBm <- 1 - pnorm(plotZeta)
tpfBm <- 1 - pnorm(plotZeta, mean = a/b, sd = 1/b)
plotBm <- data.frame(FPF = fpfBm, TPF = tpfBm)

fpfRsm <- sapply(plotZeta, RSM_xROC, lambda = lambda)
tpfRsm <- sapply(plotZeta, RSM_yROC, mu = mu, lambda = lambda, 
                nu = nu, lesDistr = lesDistr)
plotRsm <- data.frame(FPF = fpfRsm, TPF = tpfRsm)
dashedRsm <- data.frame(FPF = c(fpfRsm[1], 1), TPF = c(tpfRsm[1], 1))

fpfMax <- max(fpfRsm)
tpfMax <- max(tpfRsm)
if (fpfMax < 0.99){
  fpfCross <- (fpfMax + tpfMax) / 2
  tpfCross <- fpfCross
  endPointRSM <- data.frame(FPF = fpfMax, TPF = tpfMax)
  endPointBM <- data.frame(FPF = 1, TPF = 1)
  ds <- data.frame(FPF = c(fpfMax, fpfCross), TPF = c(tpfMax, tpfCross))
  diagonal <- data.frame(FPF = c(0, 1), TPF = c(0, 1))
  aText <- data.frame(FPF = 0.25, TPF = 0.95)
  bText <- data.frame(FPF = 0.375, TPF = 0.85)
  cText <- data.frame(FPF = 0.5, TPF = 0.45)
  dsText <- data.frame(FPF = (fpfMax + fpfCross)/2 + 0.05, TPF = (tpfMax + tpfCross)/2)
  compPlot <- ggplot() + geom_line(mapping = aes(x = FPF, y = TPF), data = plotRsm, size = 1) + 
    geom_line(mapping = aes(x = FPF, y = TPF), data = plotBm, size = 1) + 
    geom_line(data = dashedRsm, aes(x = FPF, y = TPF), linetype = 3, size = 1) +
    geom_point(data = endPointRSM, mapping = aes(x = FPF, y = TPF), shape = 15, size = 3) +
    geom_point(data = endPointBM, mapping = aes(x = FPF, y = TPF), shape = 16, size = 3) +
    geom_line(data = ds, mapping = aes(x = FPF, y = TPF), linetype = 2) + 
    geom_line(data = diagonal, mapping = aes(x = FPF, y = TPF), linetype = 2) + 
    geom_text(data = dsText, mapping = aes(x = FPF, y = TPF), label = "d[s]", parse = TRUE, size = 5) +
    geom_text(data = aText, mapping = aes(x = FPF, y = TPF), label = "a", parse = TRUE, size = 5) +
    geom_text(data = bText, mapping = aes(x = FPF, y = TPF), label = "b", parse = TRUE, size = 5) +
    geom_text(data = cText, mapping = aes(x = FPF, y = TPF), label = "c", parse = TRUE, size = 5) +
    scale_x_continuous(expand = c(0, 0)) + 
    scale_y_continuous(expand = c(0, 0)) + 
    coord_fixed(ratio = 1) #
  compPlot <- ggplotGrob(compPlot)
  compPlot$layout$clip[compPlot$layout$name=="panel"] <- "off"
  grid.draw(compPlot)
}

```


*The location of the end-point, in particular how far it is from (1,1), is a measure of search performance.* Higher search performance is characterized by the end-point moving upwards and to the left, in the limit to (0,1), corresponding to perfect search performance. It is more convenient to use a distance measure as defined next:


**Definition** 
>The perpendicular distance, $d_S$, from the end-point to the chance diagonal, plot (c), multiplied by $\sqrt{2}$, is the quantitative measure of search performance denoted by $S$.  


Using [geometry](https://en.wikipedia.org/wiki/Distance_from_a_point_to_a_line#Line_defined_by_an_equation) and Eqn. \@ref(eq:rsm-sc-FPF-TPF-max), it follows that: 


\begin{equation} 
S=\sqrt{2}d_S=\text{TPF}_{\text{max}}-\text{FPF}_{\text{max}}
(\#eq:rsm-sc-perp-distance)
\end{equation}


Therefore, search performance $S$ is given by:


\begin{equation} 
S=\exp\left ( -\lambda \right )\left (1-\sum_{L=1}^{L_{max}}f_L\left ( 1-\nu  \right )^L  \right )
(\#eq:rsm-sc-search-performance)
\end{equation}

Eqn. \@ref(eq:rsm-sc-search-performance) shows search performance is the product of two terms: the probability $\left (1-\sum_{L=1}^{L_{max}}f_L\left ( 1-\nu  \right )^L  \right )$ of finding at least one lesion times the probability $\exp\left ( -\lambda \right )$ of not finding non-lesions. This puts into mathematical form the qualitative definition of search performance as the ability to find lesions while avoiding finding non-lesions. 


Example: consider $\lambda = 0$ and $\nu = 1$. (In terms of intrinsic parameters this occurs when $\mu = \infty$.) The end-point is (0,1). The perpendicular distance from (0,1) to the chance diagonal is $\frac{1}{\sqrt{2}}$, which multiplied by $\sqrt{2}$ yields $S = 1$. The same value is obtained using Eqn. \@ref(eq:rsm-sc-search-performance). Since no NLs are found and all lesions are found, the observer never makes a mistake. One cannot improve over perfect performance and the observer does not need to use the z-sample information: he simply marks all suspicious regions found by search regardless of their z-samples. 

Search performance ranges from zero to one: $0 \le S \le 1$. The lower limit is reached if $\lambda = \infty$ or $\nu = 0$. (In terms of intrinsic parameters this occurs when $\mu = 0$.)


## Quantifying lesion-classification performance {#rsm-sc-performance}

Lesion-classification performance $C_L$ measures the ability, having found a suspicious region, to correctly classify it as a lesion, i.e., mark the location of the lesion resulting in a LL event. It is distinct from *case-classification* performance, ROC AUC, which measures the ability to distinguish between diseased and non-diseased cases. In contrast *lesion-classification* performance is a measure of the ability to distinguish between diseased and non-diseased regions, i.e., between latent NLs and latent LLs. $C_L$ is determined by the $\mu$ parameter of the RSM and is defined by the implied ROC-area of two unit variance normal distributions separated by $\mu$ (see [formula](https://dpc10ster.github.io/RJafrocRocBook/binormal-model.html#binormal-model-d-prime) for d' measure in RJafrocRocBook). 


\begin{equation}
C_L=\Phi\left ( \frac{\mu}{\sqrt{2}} \right )
(\#eq:rsm-sc-classification-performance)
\end{equation}


Since $\mu \ge 0$ it follows that $C_L$ ranges from 0.5 to 1: $0.5 \le C_L \le 1$. The lower limit occurs when $\mu = 0$ and the upper limit occurs when $\mu = \infty$.

## Discussion {#rsm-sc-discussion}

TBA

The ability to estimate search and lesion classification performances from ROC data should be of interest to researchers (particularly in the area of computer aided detection -- CAD -- algorithm design) because these two values inform us about what is limiting performance. If search performance is low then the observer is having difficulty finding lesions while minimizing finding non-lesions. In the CAD algorithm context, the *initial detection* stage needs to be further optimized. If lesion classification performance is low the observer is finding the lesions while minimizing finding non-lesions but is having difficulty correctly classifying the found lesions.  In the CAD algorithm context, the *candidate analysis* stage needs to be further optimized.    