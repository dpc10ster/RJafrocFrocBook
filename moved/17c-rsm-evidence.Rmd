# Evidence for the RSM {#rsm-evidence}


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(kableExtra)
library(seqinr)
library(RJafroc)
library(ggplot2)
library(gridExtra)
library(binom)
library(here)
```


## TBA How much finished {#rsm-evidence-how-much-finished}
70%


## Introduction {#rsm-evidence-intro}

This chapter details evidence for the validity of the radiological search model (RSM). Briefly, these are:

1.	Its correspondence to the empirical (i.e., measurement based) Kundel-Nodine model of radiological search. 
2.	In special cases, it reduces to being indistinguishable from the binormal model.
3.	It explains: 
    a. The empirical observation [@RN298] that most ROC datasets are characterized by b-parameter $b < 1$. 
    b. The empirical observation [@RN2635] that the $b$ tends to decrease as contrast increases. 
    c. The empirical observation [@RN2635], that the difference in means of the two pdfs divided by the difference in standard deviations is roughly constant.
4.	It explains data degeneracy, i.e., no interior data points, sometimes observed especially with expert observers. 
5.	It predicts FROC/AFROC and LROC curves that better fit real datasets.

As described in TBA Chapter 20, the CBM explains 3(a) and 4 while the bigamma model [@RN100] explains 3(c).

## Correspondence to the Kundel-Nodine model {#rsm-predictions-corresponence-kundel-nodine}
The strongest evidence for the validity of the RSM is its close correspondence to the Kundel-Nodine model of radiological search, which in turn is derived from eye-tracking measurements made on radiologists while they perform diagnostic tasks. These show that radiologists identify suspicious regions in a short time and this ability corresponds to the $\lambda', \nu'$ parameters of the RSM. Having found suspicious regions, the next activity uncovered by eye-tracking measurements is the detailed examination of each suspicious region in order to determine if it is a significant finding. This is where the z-sample is calculated, and this process is modeled by two unit normal distributions separated by the $\mu$ parameter of the RSM. 

Other ROC models do not share this close correspondence. The CBM model comes closest â€“ it models the probability that lesions are *found*, which is part of search performance, but the ability to *avoid finding NLs* is not modeled. Like other ROC models, CBM predicts that the point (1,1) is continuously accessible to observer, which implies zero search performance, TBA Fig. 17.6.

## The RSM can mimic the binormal model {#rsm-predictions-binormal-model-mimic}

```{r echo=FALSE, cache=TRUE}
source(here("R/rsm-evidence/PlotBMErrBar.R"))
K1 <- 500;K2 <- 700;desiredNumBins <- 5;
plotArr <- array(list(), dim = 9)
seedArr <- aucArr <- array(dim = 9)
rocDataTable <- array(dim = c(9, 2,desiredNumBins))
LmaxArr <- nuArr <- lambdaArr <- muArr <- array(dim = 9)
AzArr <- pValArr <- bArr <- aArr <- array(dim = 9)

for (Row in 1:9) {
  switch(Row,
         "1" = {seed <- 1;Lmax <- 1;mu <- 2.0;lambda <- 10
         nu <- 1;zeta1 <- -1;set.seed(seed)}, # Row 1
         "2" = {seed <- 1;Lmax <- 1;mu <- 2.5;lambda <- 10
         nu <- 1;zeta1 <- -1;set.seed(seed)}, # Row 2
         "3" = {seed <- 1;Lmax <- 1;mu <- 3.0;lambda <- 10
         nu <- 1;zeta1 <- -1;set.seed(seed)}, # Row 3
         "4" = {seed <- 2;Lmax <- 1;mu <- 2.5;lambda <- 10
         nu <- 1;zeta1 <- -1;set.seed(seed)}, # Row 4
         "5" = {seed <- 2;Lmax <- 2;mu <- 2.0;lambda <- 10
         nu <- 1;zeta1 <- -1;set.seed(seed)},# Row 5
         "6" = {seed <- 2;Lmax <- 2;mu <- 2.5;lambda <- 10
         nu <- 1;zeta1 <- -1;set.seed(seed)},# Row 6
         "7" = {seed <- 2;Lmax <- 2;mu <- 3.0;lambda <- 10
         nu <- 1;zeta1 <- -1;set.seed(seed)},# Row 7
         "8" = {seed <- 2;Lmax <- 2;mu <- 3.0;lambda <-  1
         nu <- 1;zeta1 <- -1;set.seed(seed)},# Row 8
         "9" = {seed <- 2;Lmax <- 2;mu <- 3.0;lambda <- 0.1
         nu <- 1;zeta1 <- -1;set.seed(seed)}# Row 9
  )
  muArr[Row] <- mu
  lambdaArr[Row] <- lambda
  nuArr[Row] <- nu
  LmaxArr[Row] <- Lmax
  seedArr[Row] <- seed
  perCase <- floor(runif(K2, 1, Lmax + 1))
  
  if (Lmax == 2) {
    lesDistr <- c(0.4714286, 0.5285714)
  } else if (Lmax == 1) {
    lesDistr <- 1
  } else stop("Need to run Eng program for other values of Lmax")
  
  frocDataRaw  <- SimulateFrocDataset(mu, lambda, nu, 
                                      zeta1, I = 1, 
                                      J = 1, K1, K2, 
                                      perCase = perCase, 
                                      seed = seed)
  rocDataRaw <- DfFroc2Roc(frocDataRaw)
  
  rocDataBinned <- DfBinDataset(rocDataRaw, 
                                desiredNumBins = desiredNumBins, 
                                opChType = "ROC")
  
  x1 <- table(rocDataBinned$ratings$NL[1:K1])
  if (length(x1) == 1) {
    rocDataTable[Row,1,] <- c(0,x1,0,0,0)
  } else if (length(x1) == 3) {
    rocDataTable[Row,1,] <- c(0, x1,0)
  } else if (length(x1) == 4) {
    rocDataTable[Row,1,] <- c(x1,0)
  } else if (length(x1) == 5) {
    rocDataTable[Row,1,] <- x1
  } else stop("incorrect table length 1")
  
  x2 <- table(rocDataBinned$ratings$LL[1:K2])
  if (length(x2) == 4) {
    rocDataTable[Row,2,] <- c(0,x2)
  } else if (length(x2) == 5) {
    rocDataTable[Row,2,] <- x2
  } else stop("incorrect table length 2")
  
  aucArr[Row] <- UtilAnalyticalAucsRSM(
    mu = mu, lambda = lambda,
    nu = nu, zeta1 = zeta1, lesDistr = lesDistr)$aucROC
  # print(rocDataTable[Row,,])
  # copy the last two rows of output to Eng program; 
  # delete bracket stuff leaving numbers only with spaces 
  # select format 3
  # Run Program
  # compare a, b to following values
  
  switch(Row, 
         # the following values were transferred from the 
         # Eng program output after analyzing rocDataTable 
         # generated by previous lines, using 
         # the appropriate value of Row
         "1" = {a <- 1.002;b <- 0.861; pVal <- 0.223}, # Row 1
         "2" = {a <- 1.497;b <- 0.752; pVal <- 0.460}, # Row 2
         "3" = {a <- 1.928;b <- 0.736; pVal <- 0.198}, # Row 3
         "4" = {a <- 1.221;b <- 0.682; pVal <- 0.120}, # Row 4
         "5" = {a <- 1.250;b <- 0.786; pVal <- 0.903}, # Row 5
         "6" = {a <- 1.554;b <- 0.646; pVal <- 0.592}, # Row 6
         "7" = {a <- 2.057;b <- 0.676; pVal <- 0.009}, # Row 7
         "8" = {a <- 2.391;b <- 0.405; pVal <- 0.988}, # Row 8
         "9" = {a <- 2.015;b <- 0.068; pVal <- NA}  # Row 9
  )
  aArr[Row] <- a
  bArr[Row] <- b
  AzArr[Row] <- pnorm(a/sqrt(1+b^2))
  pValArr[Row] <- pVal
  plotArr[[Row]] <- PlotBMErrBar(a, b, rocDataTable[Row,,]) + 
    ggtitle(paste0("Row = ", Row, ", a = ",  a, ", b = ", b))
}
```

ROC models assume that every case provides a finite decision variable sample. This is what permits the observer to *continuously* move the operating point to (1,1). According to the RSM a decision sample on every case is possible if $\lambda$ is large, since in the limit $\lambda \rightarrow \infty$ every case has at least one latent NL. It turns out, as shown next, that it is not necessary to go to infinite values of $\lambda$ to produce RSM-generated ratings data that are indistinguishable from those generated by the binormal model. Values of $\lambda$ around 1 to 10 are sufficient to demonstrate this fact. A factor that helps showing the indistinguishability is that the binormal model is remarkably resilient to departures from normality, its *robustness property*, demonstrated in [@RN1216]. It literally takes huge datasets, numbering in the thousands of cases, to show departures from strict normality. 

The ROC ratings datasets used in the following examples were generated by the RSM. The parameter values are listed in Table \@ref(tab:rsm-evidence-binormal-table2). RSM generated FROC datasets, in each case 500 non-diseased and 700 diseased cases were used, were converted to (highest rating) ROC datasets, each dataset was binned into 5 bins and then analyzed by an online Java program [@RN1975] which implements Metz's ROCFIT program, TBA Chapter 06, yielding the binormal parameters $a, b$ and the p-value of the chisquare goodness of fit statistic. Shown next are the binormal-model-fitted ROC curves to these datasets as well as the corresponding $a,b$ parameters. The value of Row corresponds to the row number in Table \@ref(tab:rsm-evidence-binormal-table2). 

```{r rsm-evidence-binormal-plots1-do-not-use, fig.show='hold', echo=FALSE, fig.pos='H'}
grid.arrange(plotArr[[1]], plotArr[[2]], plotArr[[3]],plotArr[[4]], nrow = 2, ncol = 2)
```             


```{r rsm-evidence-binormal-plots2, fig.cap="RSM generated ROC points and corresponding binormal model fitted curves.", fig.show='hold', echo=FALSE, fig.pos='H'}
grid.arrange(plotArr[[5]], plotArr[[6]], plotArr[[7]], plotArr[[8]], nrow = 2, ncol = 2)
```             

Fig. \@ref(fig:rsm-evidence-binormal-plots2): ROC *operating points* obtained using RSM ratings-generator and corresponding binormal model *fitted curves*. The $a, b$ parameters are shown in the figure labels. The value of `Row` corresponds to the row number in Table \@ref(tab:rsm-evidence-binormal-table2). The plots show that over a wide range of parameters RSM generated ROC data is fitted reasonably by the binormal model. The p-values of the goodness of fit statistic, see Table \@ref(tab:rsm-evidence-binormal-table2), are all in the range of what is considered an acceptable fit to a model. As far as the binormal model-fitting software is concerned, the counts data arose from two *effectively normal distributions* (i.e., apart from the intrinsic uncertainty due to allowed arbitrary monotone transformations). Even with the large number of cases, sampling variability affects the binormal model fits: e.g., the binormal model curves in plots labeled "2" and "4" differ only in seed values. The hooks near (1,1) in the binormal ROC fitted curves are not easily visible but are nevertheless present as each of the b-parameters in Table \@ref(tab:rsm-evidence-binormal-table2) is less than unity. The error bars are exact 95% binomial confidence intervals on the operating points.   

**Since the binormal model has been used successfully for almost six decades, the ability to the RSM to mimic it is an important justification for the validity of the RSM.**


```{r  rsm-evidence-do-one-row, echo=FALSE}
do_one_row <- function(Row,seed,Lmax,mu,lambda,auc,a,b,Az,pVal){

ret <- c(
  Row,
  seed,
  Lmax,
  mu,
  lambda,
  format(auc, digits = 3),
  a,
  b,
  format(Az, digits = 3),
  pVal)

return(stresc(ret))
}
```


```{r rsm-evidence-all-cells, echo=FALSE}
allCells <- array("", dim = c(8,10))

for (i in 1:8) {
  allCells[i,] <- do_one_row (i,seedArr[i],LmaxArr[i],muArr[i],
                              lambdaArr[i],
                              aucArr[i], aArr[i], 
                              bArr[i],AzArr[i], pValArr[i])  
}
```



```{r rsm-evidence-binormal-table2, echo=FALSE}
cells = array(dim = c(8,10))

for (j in 1:8) cells[j,]  <- allCells[j,]

df <- as.data.frame(cells, stringsAsFactors = FALSE)
colnames(df) <-c("Row", "s", "L", "$\\mu$", "$\\lambda$", "A", "a", "b",  "Az", "pVal")
# escape = FALSE is critical in getting Math right
kbl(df, caption = "Simulating ROC binned ratings data using the RSM and fitting the ratings using the binormal model; s is the seed, L is the maximum number of lesions per case, A is the RSM-predicted ROC-AUC, Az is the binormal model fitted AUC and $\\nu = 1$ for all datasets.", booktabs = TRUE, escape = FALSE) %>% kable_styling(latex_options = c("basic", "scale_down", "HOLD_position"), row_label_position = "c") 
```


Table \@ref(tab:rsm-evidence-binormal-table2): Results of simulating ROC ratings tables using seeds and RSM parameter values specified in columns 2 â€“ 5 and fitting each ratings table using the binormal model. The corresponding binormal model fitted ROC curves are shown in Fig. \@ref(fig:rsm-evidence-binormal-plots2). The number of non-diseased cases was 500, the number of diseased cases was 700, and the reporting threshold $\zeta_1 = -1$. 

Of interest in Table \@ref(tab:rsm-evidence-binormal-table2) is the observation that $b < 1$, and the qualities of the fits are quite good (p > 0.001 is generally considered acceptable, see [@RN300], 3rd edition, page 779). 

One expects $A \equiv AUC_{ROC}^{RSM}$ to exceed the binormal fitted value $A_z$. This has to do with the "proper" property of the RSM-ROC curve, which implies an *ideal observer*, while the binormal model predicts "improper" ROC curves, TBA Chapter 20. For rows 2 and 3, the expected orderings are reversed but the magnitudes of the discrepancies are small. This is because RSM-predicted values are *not* subject to sampling variability as they are derived by numerical integration, whose estimation error is very small compared to sampling error. In contrast, the estimates of $A_z$ are subject to sampling variability, even though large numbers of cases were used. Row-4 repeats Row-2 with a different value of `seed`: this time the expected ordering is observed $A > Az$. 


## Empirical observations
As summarized previously, there are three empirical observations regarding binormal parameters: 

* $b < 1$. 
* $b$ decreases as $a$ increases. 
* For fixed experimental conditions $R_{Swets} \equiv \frac {a}{1-b}$ is approximately constant.  


## Explanation for $b < 1$
The RSM-predicted ROC curves are consistent with empirical observations [@RN298] that observed ROC data, when fitted by the unequal variance binormal model, yield $b < 1$, implying that the diseased case pdf is wider than the non-diseased case pdf. The RSM provides an explanation for this: diseased cases yield two types of z-samples, namely NL z-samples from a zero-centered unit variance normal distribution and LL z-samples from a  $\mu$-centered unit variance normal distribution. The resulting *mixture distribution* is expected, when one attempts to fit it with a normal distribution, to yield standard deviation for diseased cases greater than 1, or, equivalently, $b < 1$. The fit is not expected to be ideal, but it is known that for relatively small numbers of cases, as is true with clinical data sets, it is difficult to detect deviations from strict normality; indeed, the binormal model is quite robust with respect to deviations from strict normality [@RN298]. Several examples of this were evident in the goodness of fit p-values in Table \@ref(tab:rsm-evidence-binormal-table2), which show good binormal fits to RSM generated data even with 1200 cases. 


```{r rsm-evidence-pdfs, echo=FALSE}
K2 <- 700
Lmax <- 1
Lk2 <- floor(runif(K2, 1, Lmax + 1))
lesDistr <- 1
plotArr <- array(list(), dim = c(2,2))
labels <- LETTERS[1:4]; dim(labels) = c(2,2);labels <- t(labels)
muArr <- c(2,3)
lambda <- 1
nuArr <- c(0.15,0.25)
L <- 1  # to show wider pdfs of diseased cases
for (i in 1:length(muArr)) {
  mu <- muArr[i]
  for (j in 1:length(nuArr)) {
    nu <- nuArr[j]
    ret1 <- PlotRsmOperatingCharacteristics(mu,
                                            lambda,
                                            nu,
                                            lesDistr = lesDistr,
                                            legendPosition  = "none")
    plotArr[[i,j]] <- ret1$PDFPlot + 
      ggtitle(paste0(labels[i,j], ", mu = ", muArr[i], ", nu = ", nuArr[j]))
  }
}

```



```{r rsm-evidence-pdf-plots, fig.cap="pdfs along with the parameter values. The dotted curves correspond to non-diseased cases while solid curves correspond to diseased cases.", fig.show='hold', echo=FALSE, fig.pos='H'}
grid.arrange(plotArr[[1,1]], plotArr[[1,2]], plotArr[[2,1]], plotArr[[2,2]], nrow = 2, ncol = 2)
```             


Fig. \@ref(fig:rsm-evidence-pdf-plots): This figure provides an explanation for empirical observation $b < 1$. Displayed are pdfs along with the parameter values. For all plots $\lambda = 1$ and $L_{max} = 1$. The dotted curves correspond to non-diseased cases while the solid curves correspond to diseased cases. The solid curves are broader than the dotted ones. In (A) and (B) the solid curve is noticeably broader. In (D) there is a hint of a secondary peak at zero, which is quite prominent in (C), which corresponds to the largest $\mu$ and the smallest $\nu$. In each case the resulting mixture distribution is expected to lead to a larger estimate of standard deviation of the assumed normal distribution of diseased cases relative to non-diseased cases. 


## Explanation of Swets et al observations 

More than 55 years ago, [@RN2635] noticed in two non-medical imaging contexts:
 
* The standard deviation of the non-diseased distribution divided by the standard deviation of the diseased distribution, tended to decrease as contrast increased. In binormal parameter terms, $b$ decreases as $a$ increases.

* The ratio $R_{Swets} \equiv \Delta(mean) / \Delta(\sigma)$, henceforth referrd to as the Swets Ratio, has been conjectured to be approximately constant for a fixed set of experimental conditions. $\Delta(mean)$ is the separation of the means of the two distributions and $\Delta(\sigma)$ is the difference of the two standard deviations (diseased minus non-diseased). In binormal parameter terms, $R_{Swets} \equiv \frac{a}{1-b}$ is supposed to be approximately constant ^[The separation is $a$, the wider signal distribution has standard deviation unity while the narrower noise distribution has standard deviation $b$.].

The second observation implies a peculiar relation between the $a$ and $b$ parameters. Recall Figure \@ref(fig:binormal-model-ab2-mu-sigma), Plot A, which shows the definitions of the binormal $a$ and $b$ parameters. The diseased pdf has unit standard deviation, while the non-diseased has standard deviation $b < 1$, and the separation of the two distributions is $a$. The constancy of Swets Ratio implies that as $a$ increases $b$ decreases (which implies that the first Swets observation is actually contained in the second) so as to increase $1-b$ by the same factor. Since $b$ is a standard deviation, i.e., $b > 0$, it can only shrink so far, and eventually, for large enough $a$, the presumed constancy must fail. In particular, as $b$ approaches unity (corresponding to the equal variance binormal model) the ratio must approach infinity. Nevertheless, it is interesting to use the RSM to test this hypothesis.

Testing over a range of $\mu$ using binormal model maximum likelihood fitting is direct but cumbersome and subject to failure as it depends on convergence of the binormal model algorithm, which is problematical for larger values of $\mu$, which lead to degenerate datasets. Instead, the following method was used. The search model predicted pdfs were normalized so that they individually integrated to unit areas over the continuous sections. Normalization was accomplished by dividing the non-diseased pdf by the x-coordinate of the end-point, and the diseased pdf by the y-coordinate of the end-point. The means and standard deviations of these distributions were calculated by numerical integration. Since the binormal model is not used, the effective binormal parameters will henceforth be referred to as $a_{eff}$ and $b_{eff}$. In this notation, the Swets Ratio is $R_{Swets} \equiv \frac{a_{eff}}{1-b_{eff}}$.  

The following equations describe the calculations involved, which are implemented in the code:

\begin{equation}
\left. 
\begin{aligned}
\left \langle x \right \rangle_N = & \int_{-\infty}^{\infty} xf_N(x) dx \\
\left \langle x \right \rangle_D = & \int_{-\infty}^{\infty} xf_D(x) dx \\
\sigma_N^2 = & \int_{-\infty}^{\infty} \left (x - \left \langle x \right \rangle_N  \right )^2f_N(x) dx \\
\sigma_D^2 = & \int_{-\infty}^{\infty} \left (x - \left \langle x \right \rangle_D  \right )^2f_D(x) dx \\
\end{aligned}
\right \}
(\#eq:rsm-evidence-x-sigmax2)
\end{equation}


Subscripts $N$ and $D$ refer to non-diseased and diseased cases, respectively, while $f(x)$ is the normalized $pdf$ function. The effective binormal parameters are defined as:


\begin{equation}
\left. 
\begin{aligned}
a_{eff} = & \frac{\left \langle x \right \rangle_D - \left \langle x \right \rangle_N  } {\sigma_D}\\
b_{eff} = & \frac{\sigma_N}{\sigma_D}\\
R_{Swets} = & \frac{a_{eff}}{1 - b_{eff} }
\end{aligned}
\right \}
(\#eq:rsm-evidence-delta-mean-sigma)
\end{equation}


Varying experimental conditions were simulated by individually varying two of the three parameters of the RSM under the constraint that the RSM predicted AUC (assuming $\zeta_1 = -\infty$) remains constant at a specified value. Without this constraint, variation of a single parameter, e.g., $\mu$, would cause AUC to vary over the entire range 0.5 to 1, which is uncharacteristic of radiologists interpreting the same case set. Rather, we assume that observers characterized by different RSM parameters nevertheless converge to roughly the same RSM-AUCs. In other words, they trade deficiencies in one area (e.g., finding too many NLs, large $\lambda$) with increased performance in other areas (e.g., finding more lesions, i.e., larger $\nu$, and/or greater perceptual signal to noise ratio, i.e., larger $\mu$).


In the code, the number of lesions per diseased case was set to one. The function `FindParamFixAuc()` finds the missing RSM parameter, indicated by initializing it with `NA`. The function `effectiveAB()` calculates the separation $a_{eff}$ and standard deviation ratio $b_{eff}$ (non-diseased to diseased) of the two distributions, after normalizing each to unit area. 



```{r main-rsm-swets-observations0, echo=FALSE}
source(here("R/rsm-evidence/PlotBMErrBar.R"))
source(here("R/rsm-evidence/effectiveAB.R"))
source(here("R/rsm-evidence/FindParamFixAuc.R"))
source(here("R/rsm-evidence/rsmSupportFns.R"))

logseq <- function( d1, d2, n) {
  logf <- log(d2/d1)/(n-1)
  return (exp(seq(log(d1), log(d2), logf)))
}

# parameters are adjusted to attain this value; 0.7 or 0.8
do_one_value <- function (RsmRocAuc) {
  
  lesDistr <- 1
  
  # Part A
  dfA <- data.frame()
  lambda <- 2
  muArr <- logseq(2,5,10)
  for (i in 1:length(muArr)) {
    mu <- muArr[i]
    nu <- NA   # NA indicates this is to be varied
    
    retParms <- FindParamFixAuc(mu, lambda, nu, lesDistr, RsmRocAuc)
    if (!is.na(retParms)) nu <- retParms else next
    ret <- effectiveAB(mu, lambda, nu, lesDistr)
    a <- ret$a
    b <- ret$b
    R_Swets  <-  a/(1-b)
    
    ret <- UtilIntrinsic2PhysicalRSM(mu, lambda, nu)
    lambdaP <- ret$lambdaP
    nuP <- ret$nuP
    
    dfA <- rbind(dfA, data.frame(
      AUC = RsmRocAuc,
      mu = mu, 
      lambda = lambdaP,
      nu = nuP,
      a = a,
      b = b, 
      R_Swets = R_Swets
    ))
  }
  
  # Part B
  dfB <- data.frame()
  nu <- 1
  lambdaArr <- logseq(1, 5, 10)
  for (i in 1:length(lambdaArr)) {
    lambda <- lambdaArr[i] 
    mu <- NA  # NA indicates this is to be varied
    
    retParms <- FindParamFixAuc(mu, lambda, nu, lesDistr, RsmRocAuc)
    if (!is.na(retParms)) mu <- retParms else next
    ret <- effectiveAB(mu, lambda, nu, lesDistr)
    a <- ret$a
    b <- ret$b
    R_Swets  <-  a/(1-b)

    ret <- UtilIntrinsic2PhysicalRSM(mu, lambda, nu)
    lambdaP <- ret$lambdaP
    nuP <- ret$nuP
    
    dfB <- rbind(dfB, data.frame(
      AUC = RsmRocAuc,
      mu = mu, 
      lambda = lambdaP,
      nu = nuP, 
      a = a,
      b = b, 
      R_Swets = R_Swets
    ))
  }
  
  # Part C
  dfC <- data.frame()
  mu <- 2
  lambdaArr <- logseq(0.1, 5, 10)
  for (i in 1:length(lambdaArr)) {
    lambda <- lambdaArr[i]
    nu <- NA;  # NA indicates this is to be varied
    
    retParms <- FindParamFixAuc(mu, lambda, nu, lesDistr, RsmRocAuc)
    if (!is.na(retParms)) nu <- retParms else next
    ret <- effectiveAB(mu, lambda, nu, lesDistr)
    a <- ret$a
    b <- ret$b
    R_Swets  <-  a/(1-b)
    
    ret <- UtilIntrinsic2PhysicalRSM(mu, lambda, nu)
    lambdaP <- ret$lambdaP
    nuP <- ret$nuP
    
    dfC <- rbind(dfC, data.frame(
      AUC = RsmRocAuc,
      mu = mu, 
      lambda = lambdaP,
      nu = nuP, 
      a = a,
      b = b, 
      R_Swets = R_Swets
    ))
  }
  return(list(
    dfA = dfA,
    dfB = dfB,
    dfC = dfC
  ))
}

```


```{r main-rsm-swets-observations1, echo=FALSE}
ret <- do_one_value (0.7) 
dfA <- ret$dfA;dfA <- format(dfA, digits = 4)
dfB <- ret$dfB;dfB <- format(dfB, digits = 4)
dfC <- ret$dfC;dfC <- format(dfC, digits = 4)
```



Perhaps the best way of illustrating the near constancy of the Swets Ratio is by fixing $\lambda = 2$ and varying $\mu$ and $\nu$ to keep AUC constant, as in Table \@ref(tab:rsm-evidence-table1A). This results in a large range over which $\mu$ is varied, from `r min(dfA$mu)` to `r max(dfA$mu)`. The RSM $\mu$ parameter controls the separation of non-diseased and diseased pdfs and as such directly affects the binormal $a_{eff}$ parameter. Hence the corresponding large range for $a_{eff}$, from `r min(dfA$a)` to `r max(dfA$a)`. The RSM $\nu'$ parameter is relatively constant, ranging from `r min(dfA$nu)` to `r max(dfA$nu)`. Note that the *physical $\lambda'$ and $\nu'$ (i.e., primed) quantities* are shown in the table. This table shows that the Swets Ratio is near constant, ranging from `r min(dfA$R_Swets)` to `r max(dfA$R_Swets)`. Note the increase in the ratio for the largest value of $b_{eff}$, i.e., that closest to unity, which, as noted earlier, is as expected. 


```{r rsm-evidence-table1A, echo=FALSE}
colnames(dfA) <-c("$AUC$", "$\\mu$", "$\\lambda'$", "$\\nu'$", "$a_{eff}$", "$b_{eff}$", "$\\frac{a_{eff}}{1-b_{eff}}$")
# escape = FALSE is critical in getting Math right
kbl(dfA, caption = "Here $\\lambda = 2$ is held constant while the other two parameters are varied to keep AUC at 0.7. The last column lists the Swets Ratio. Note the inverse relation between $a_{eff}$ and $b_{eff}$.", booktabs = TRUE, escape = FALSE) %>% collapse_rows(columns = c(1, 3), valign = "middle") %>% kable_styling(latex_options = c("basic", "scale_down", "HOLD_position"), row_label_position = "c") 
```


In Table \@ref(tab:rsm-evidence-table1B) the parameter $\nu = 1$ is held fixed while $\mu$ and $\lambda$ are varied. This time $a_{eff}$ is relatively constant, ranging from `r min(dfB$a)` to `r max(dfB$a)`, while $b_{eff}$ is very close to unity, ranging from `r min(dfB$b)` to `r max(dfB$b)`, leading to the very large and varying values of the Swets Ratio, ranging from `r min(dfB$R_Swets)` to `r max(dfB$R_Swets)`.



```{r rsm-evidence-table1B, echo=FALSE}
colnames(dfB) <-c("$AUC$", "$\\mu$", "$\\lambda'$", "$\\nu'$", "$a_{eff}$", "$b_{eff}$", "$\\frac{a_{eff}}{1-b_{eff}}$")
# escape = FALSE is critical in getting Math right
kbl(dfB, caption = "Here $\\nu = 1$ is held constant while the other two parameters are varied to keep AUC at 0.7. The last column lists the Swets Ratio. Note the inverse relation between $a_{eff}$ and $b_{eff}$.", booktabs = TRUE, escape = FALSE) %>% collapse_rows(columns = c(1, 3), valign = "middle") %>% kable_styling(latex_options = c("basic", "scale_down", "HOLD_position"), row_label_position = "c") 
```



In Table \@ref(tab:rsm-evidence-table1C), the final example, $\mu = 2$ is held constant but the other two parameters $\lambda, \nu$ are varied to keep AUC constant. This time the inverse dependence between $a_{eff}$ and $b_{eff}$ is *not* observed: while $a_{eff}$ decreases monotonically as one moves down the column, $b_{eff}$ shows a minimum around the seventh row of this table. Except for the first column, which corresponds to the largest value of $b_{eff}$, the Swets Ratio is near constant. 

In practice datasets with $b > 1$ are occasionally observed. These would lead to a negative Swets Ratio. 


```{r rsm-evidence-table1C, echo=FALSE}
colnames(dfC) <-c("$AUC$", "$\\mu$", "$\\lambda'$", "$\\nu'$", "$a_{eff}$", "$b_{eff}$", "$\\frac{a_{eff}}{1-b_{eff}}$")
# escape = FALSE is critical in getting Math right
kbl(dfC, caption = "Here $\\mu = 2$ is held constant while the other two parameters are varied to keep AUC at 0.7. The last column lists the Swets Ratio. Note the lack of an inverse relation between $a_{eff}$ and $b_{eff}$.", booktabs = TRUE, escape = FALSE) %>% collapse_rows(columns = c(1, 2), valign = "middle") %>% kable_styling(latex_options = c("basic", "scale_down", "HOLD_position"), row_label_position = "c") 
```


Swets et al observations are based on only two datasets (as best as I can tell) and their observed value was $\frac{a}{1-b} \approx 4$. As shown above, depending on the value of $b$, the ratio can reach very large values if $b \rightarrow 1$, or even negative values if $b > 1$. Therefore, the Swets Ratio observation is probably not generalizable. Nevertheless, as long as the $\mu$ parameter is varied over a wide range and AUC is held constant, the RSM does predict the inverse dependence of the binormal $a$ and $b$ parameters and the near constancy of the Swets Ratio.

	

## Explanation of data degeneracy
*An ROC dataset is said to be degenerate if the corresponding ROC plot does not have any interior points.* Data degeneracy is a significant problem faced by the binormal model [@RN1081; @metz1999proper;@RN1083]. Degenerate datasets cannot be analyzed by the binormal model. The RSM provides a natural explanation for degeneracy, and moreover, as shown in TBA Chapter 19, such datasets are readily fitted by the RSM. [The CBM model [@RN1501] provides an alternative explanation for the data degeneracy and a method for fitting such datasets.]

The possibility of degeneracy can be appreciated by examining Fig. \@ref(fig:rsm-evidence-binormal-plots2), in particular the plot labeled "Row = 8", i.e., corresponding to the highest values of $\mu$, for which the accessible portion of the RSM-generated ROC curve shrinks and approaches the top-left corner of the plot. The operating points will be clustered near the initial near-vertical section of the ROC curve. *It will be difficult to get such observers to generate appreciable numbers of false positives.* Instructions such as "spread your ratings" [@RN113] or the use "continuous" ratings [@RN1083] may not work. *In any case, interfering with the radiologist's readings style to make the data easier to analyze is undesirable experimental practice.* To the experimenter it will appear that the observer is not cooperating, when in fact they are being perfectly reasonable. A similar issue affected Dr. Swensson's LROC analysis method [@swensson1996unified] in which (originally) every case had to be assigned a "most-suspicious" region, even if the radiologist thought the case was perfectly normal. This met with resistance from radiologists. Radiologists don't like to be told, "even if you believe the case is definitely normal, there must be some region that is least normal, or most suspicious". All of these semantic difficulties go away if one abandons the premise that every case must generate a z-sample. ^[In later versions of his software, Dr. Swensson removed the forced localization requirement and instead did it in the software by sampling a random number generator.] 


## Predictions of observed FROC/AFROC/LROC curves
Besides predicting ROC, FROC and AFROC curves, as shown in this TBA chapter, the RSM also predicts LROC curves [@RN1654]. Moreover, these are generally better fits to experimental data, since the RSM does not allow the AFROC and LROC curve to go continuously to (1,1), as do earlier models [@chakraborty1989maximum; @chakraborty1990free; @swensson1996unified]. ^[As a historical note, the FROCFIT and AFROC software [@chakraborty1989maximum; @chakraborty1990free] developed by me in 1989 was more successful at fitting microcalcification data than mass data (private communication, Prof. Heang-Ping Chan, ca. 1990). This is consistent with the premise that the microcalcification task is characterized by larger $\lambda$ than the mass task. Radiologists literally use a magnifying glass (a physical on or a software implementation) to search each image for the much smaller specks, and this increases the potential for finding NLs. Mass detection is more a function of the global gestalt view described in the previous chapter. Larger $lambda$ yields an FROC curve that traverses more to the right than the corresponding mass curve. The FROCFIT program allows the FROC curve to go far to the right and reach unit ordinate, which is not observed with mass data, but could approximate microcalcification data, especially in the lower-left region of the curve.] 


## Discussion / Summary {#rsm-evidence-discussion-summary}
Evidence for the RSM is summarized. Its correspondence to the empirical Kundel-Nodine model of visual search that is grounded in eye-tracking measurements. It reduces in the limit of large $\lambda$, which guarantees that every case will yield a decision variable sample, to the binormal model; the predicted pdfs in this limit are not strictly normal, but deviations from normality would require very large sample size to demonstrate. Examples were given where even with 1200 cases the binormal model provides statistically good fits. Since the binormal model has proven quite successful in describing a large body of data, it satisfying that the RSM can mimic it. The RSM explains most empirical results regarding binormal model fits: the common finding that b < 1; that $b$ decreases with increasing lesion contrast; and the finding that the difference in means divided by the difference in standard deviations is fairly constant for a fixed experimental situation. The RSM explains data degeneracy, especially for radiologists with high expertise.


## The Wagner review

The two RSM papers [@chakraborty2006search; @chakraborty2006roc] were honored in Physics in Medicine and Biology by being included in a list of 25 papers deemed the "Highlights of 2006". As stated by the publisher: 

> I am delighted to present a special collection of articles that highlight the very best research published in Physics in Medicine and Biology in 2006. Articles were selected for their presentation of outstanding new research, receipt of the highest praise from our international referees, and the highest number of downloads from the journal website.

One of the reviewers was the late Dr. Robert ("Bob") F. Wagner â€“ he had an open-minded approach to imaging science and a unique style. The author reproduces one of his comments with minor edits, as it pertains to the most interesting and misunderstood prediction of the RSM, namely its constrained end-point property.

> I'm thinking here about the straight-line piece of the ROC curve from the max to (1, 1). 
1.	This can be thought of as resulting from two overlapping uniform distributions (thus guessing) far to the left in decision space (rather than delta functions). Please think some more about this point--because it might make better contact with the classical literature. 
2.	BTW -- it just occurs to me (based on the classical early ROC work of Swets & co.) -- that there is a test that can resolve the issue that I struggled with in my earlier remarks. The experimenter can try to force the reader to provide further data that will fill in the space above the max point. If the results are a straight line, then the reader would just be guessing -- as implied by the present model. If the results are concave downward, then further information has been extracted from the data. This could require a great amount of data to sort out--but it's an interesting point (at least to me).


Dr. Wagner made two interesting points. Here is ny response (ca. 2006):

> The need for delta functions at negative infinity can be seen from the following argument. Let us postulate two constrained width pdfs with the same shapes but different areas, centered at a common value far to the left in decision space, but not at negative infinity. These pdfs would also yield a straight-line portion to the ROC curve. However, they would be inconsistent with the search model assumption that some images yield no decision variable samples and therefore cannot be rated in bin ROC:2 or higher. Therefore, if the distributions are as postulated above then choice of a cutoff in the neighborhood of the overlap would result in some of these images being rated 2 or higher, contradicting the RSM assumption.  The delta function pdfs at negative infinity are seen to be a consequence of the search model. 

In hindsight, I should never have introduced the delta functions and simply accepted the pdfs not integrating to unity for the simple reason that all cases do not generate decision variable samples.

> One could argue that when the observer sees nothing to report then he starts guessing and indeed this would enable the observer to move along the dashed portion of the curve. This argument implies that the observer knows when the threshold is at negative infinity, at which point the observer turns on the guessing mechanism (the observer who always guesses would move along the chance diagonal). In my judgment, this is unreasonable. The existence of two thresholds, one for moving along the non-guessing portion and one for switching to the guessing mode would require abandoning the concept of a single decision rule. To preserve this concept one needs the delta functions at negative infinity.

Regarding Dr. Wagner's second point, it would require effort to sort out whether forcing the observer to guess will fill in the dashed portion of the curve. Given the bad consequences of guessing I believe that in the clinical situation, the radiologist will never guess. If the radiologist sees nothing to report, nothing will be reported. 




